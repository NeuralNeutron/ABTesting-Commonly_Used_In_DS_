{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d59e212",
   "metadata": {},
   "source": [
    "Letâ€™s imagine you work on the product team at a medium-sized online e-commerce business. The UX designer worked really hard on a new version of the product page, with the hope that it will lead to a higher conversion rate. The product manager (PM) told you that the current conversion rate is about 13% on average throughout the year, and that the team would be happy with an increase of 2%, meaning that the new design will be considered a success if it raises the conversion rate to 15%.\n",
    "\n",
    "1) FORMULATING A HYPOTHESIS\n",
    "\n",
    "First, we will need to establish a hypothesis, in order to ensure our interpretation is correct and rigorous.\n",
    "\n",
    "As we do not know, whether the new design will perform better or worse, we will choose to use a two-tailed-test:\n",
    "\n",
    "Ho:P=Po\n",
    "\n",
    "Ha:P=/=Po\n",
    "\n",
    "where P and Po will stand for the conversion rate of the new and old design.\n",
    "\n",
    "We will also set a confidence level of 95%:\n",
    "\n",
    "a=0.05\n",
    "\n",
    "The a value is the threshold we have set ourselves. What this means is that if the probability of observing a result as extreme or more(p-value) is lower than a, then we will reject the Null hypothesis. Since our a=0.05, our confidence level is 95%\n",
    "\n",
    "2) CHOOSING THE VARIABLES\n",
    "\n",
    "In order to test our hypothesis, we need two groups:\n",
    "\n",
    "A control group ( shown the old design)\n",
    "A treatment broup ( shown the new design)\n",
    "This is our Independent Variable. Even though we are testing for an increase in conversion rate. We have two groups to control for other variables that could have an effect on our results, for example seasonality:\n",
    "\n",
    "When we have a control group, we can compare their direct results with that of the treatment group as the only systematic difference between the groups is the webpage they are shown.\n",
    "\n",
    "Our Dependant Variable is what we are trying to measure. In this case it is the conversion rate. We can apply a binary variable classification to this: 0 - User Bought during their session 1 - User did not buy during their session\n",
    "\n",
    "This allows us to easily calculate the mean for each group to get the conversion rate of each design.\n",
    "\n",
    "3) CHOOSING A SAMPLE SIZE\n",
    "\n",
    "It is valuable to note, we will not test our whole user base, the conversion rate we will get will only be estimates of the true rate\n",
    "\n",
    "The best way to consider this is: The number of people we decide to capture in each group will impact the precision of our estimated conversion rates. So the larger our sample the more precise our estimates and the more likely we will detect a difference between the two groups. However, the larger our sample, the more expensive and time consuming our study becomes.\n",
    "\n",
    "So the questions is: How many people should we have in each group?\n",
    "\n",
    "We can use a method called Power Analysis. It is made up of a few factors:\n",
    "\n",
    "Power of the test (1 - beta) - This is the probability of finding a statistical difference, between the groups in our test, when a difference is actually present. Usually this is 0.8 by convention (can be explored)\n",
    "\n",
    "Alpha value(a) - The critical value we set earlier to 0.05\n",
    "\n",
    "Effect size - How big of a difference we expect there to be between the conversion rates.\n",
    "\n",
    "Since we know the team are happed with a 2% difference, we can use the 13 and 15% to calculate the effect size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96d0160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4720\n"
     ]
    }
   ],
   "source": [
    "# In python there are already built in functions that take care of these calculations for us\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## This is plot styling preferences\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "font = {'family' : 'Helvetica',\n",
    "        'weight' : 'bold',\n",
    "        'size' : 14}\n",
    "\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "effect_size = sms.proportion_effectsize(0.13, 0.15)    ## This calculates our effect size based on our expected rates\n",
    "\n",
    "required_n = sms.NormalIndPower().solve_power(         ## This calculates the sample size needed\n",
    "    effect_size,\n",
    "    power=0.8,\n",
    "    alpha=0.05,\n",
    "    ratio=1\n",
    "    )\n",
    "\n",
    "required_n =ceil(required_n)      #Rounds up to the next whole number\n",
    "\n",
    "print(required_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2034426",
   "metadata": {},
   "source": [
    "We can see above that we would need 4720 observation for each group.\n",
    "\n",
    "As we have set the power parameter to 0.8, in practice this means if there exists an actual difference in conversion rate between our designs. Assuming the difference is the one we estimated (13% vs 15%), we have about 80% chance to detect it as statistically significant in our test with the sample size we calculated\n",
    "\n",
    "4) COLLECTING AND PREPARING THE DATA\n",
    "\n",
    "At this point we know exactly what size sample we would need. At this point you would usually work with the engineering team to get the data.\n",
    "\n",
    "However to keep going, we will use a online dataset as a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3a3ce",
   "metadata": {},
   "source": [
    "Lets make sure all the control group are seeing the correct page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03452ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['group'], df['landing_page'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e852fe8",
   "metadata": {},
   "source": [
    "Before we go ahead and sample the data to get our subset, lets make sure there are no users that have been sampled multiple times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_counts = df['user_id'].value_counts(ascending=False)\n",
    "multi_users = session_counts[session_counts > 1].count()\n",
    "\n",
    "print(multi_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8f63e",
   "metadata": {},
   "source": [
    "We can see there are 3894 users, that appear more than once. AS this is fairly low in comparison to total number of data points\n",
    "We will go ahead and remove them from the Dataframe using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "users_to_drop = session_counts[session_counts > 1].index\n",
    "\n",
    "df=df[~df['user_id'].isin(users_to_drop)]\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8d9e6",
   "metadata": {},
   "source": [
    "So we can see above we have removed 3894 duplicate user ids in each category (7788) from the total of 294478, giving us a unique total of 294478 - 7788 = 286690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f59737",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['group'], df['landing_page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742efe7",
   "metadata": {},
   "source": [
    "5) SAMPLING\n",
    "\n",
    "Now that our dataframe is nice and clean, we can proceed and sample the advised 4720 entries for each of the groups. We will use the pandas sample function to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_sample = df[df['group'] == 'control'].sample(n=required_n)\n",
    "treatment_sample = df[df['group'] == 'treatment'].sample(n=required_n)\n",
    "\n",
    "ab_test = pd.concat([control_sample, treatment_sample], axis=0)\n",
    "ab_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ab_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test['group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00e6c5",
   "metadata": {},
   "source": [
    "At this point, everything looks good. we have a even split of control and treatment group. We can analyse the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12974e",
   "metadata": {},
   "source": [
    "6) VISUALIZING THE RESULTS\n",
    "\n",
    "Lets calculate some basic statistics to get an idea of what our samples look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2dbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rates = ab_test.groupby('group')['converted']\n",
    "\n",
    "std_p = lambda x: np.std(x, ddof=0)    ##Std Deviation of the proportion\n",
    "se_p = lambda x: stats.sem(x, ddof=0)  ##Std Error of the proportion (std/sqrt(n))\n",
    "\n",
    "conversion_rates = conversion_rates.agg([np.mean, std_p, se_p])\n",
    "conversion_rates.columns = ['conversion_rate', 'std_deviation', 'std_error']\n",
    "\n",
    "conversion_rates.style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ca706",
   "metadata": {},
   "source": [
    "Judging by the stats above, it does look like our two designs similarly, our new design actually performed slightly worse\n",
    "\n",
    "Now lets plot the data, to make the results easier to digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f07815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.barplot(x=ab_test['group'], y=ab_test['converted'], ci=False)\n",
    "\n",
    "plt.ylim(0, 0.17)\n",
    "plt.title('Conversion rate by group', pad=20)\n",
    "plt.xlabel('Group', labelpad=15)\n",
    "plt.ylabel('Converted (proportion)', labelpad=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd6648",
   "metadata": {},
   "source": [
    "Our sampled conversion rates ar close and both a lot worse than originally assumed (13%). There may be a difference when sampling from a population. Now we have to question, is this difference statistically significant??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24905a40",
   "metadata": {},
   "source": [
    "6) TESTING THE HYPOTHESIS\n",
    "\n",
    "The final step in our analysis, is testing our initial hypothesis. Since our sample is a large sample. We can use a normal approximation for calculating our P value. In other wors a Z-test\n",
    "\n",
    "We will use the statsmodels.stats.proportion to get the p-value and confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800da9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "\n",
    "control_results = ab_test[ab_test['group'] == 'control']['converted']\n",
    "treatment_results = ab_test[ab_test['group'] == 'treatment']['converted']\n",
    "\n",
    "n_con = control_results.count()\n",
    "n_treat = treatment_results.count()\n",
    "successes = [control_results.sum(), treatment_results.sum()]\n",
    "nobs = [n_con, n_treat]\n",
    "\n",
    "z_stat, pval = proportions_ztest(successes, nobs=nobs)\n",
    "(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)\n",
    "\n",
    "print(f'Z score: {z_stat:.2f}')\n",
    "print(f'P value: {pval:.3f}')\n",
    "print(f'ci 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')\n",
    "print(f'ci 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182f959",
   "metadata": {},
   "source": [
    "As our P valueis 0.119, is larger than our 0.05 threshold, We reject the null hypothesis and the change in design did have an effect of conversion rate, just that it was negative. Our new design performed worse than our old one.\n",
    "\n",
    "If we also look at the confidence intervals, our old design did not achieve its baseline expectation of 13%\n",
    "\n",
    "\n",
    "With all this being considered we need to return to the design stage and assess what we can do to improve user usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d642ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
